{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSg5U4D5I35S"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/main/12-architectures/AutoEncoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1oGi88ZU8eN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm, metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1607718262398,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "8OOFPFLiV-mh",
    "outputId": "378ba431-4924-4e5a-beb9-a4c05c5a5067"
   },
   "outputs": [],
   "source": [
    "# make sure the results are reproducible\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# run all computations on the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Running computations with %s' % torch.device(device))\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohZHyOTnI35b"
   },
   "source": [
    "## MNIST\n",
    "\n",
    "We will use the well-known MNIST dataset, again. It consists of relatively small $28 \\times 28$ pixel images of digits. The goals of the dataset is to classify the digit images to the actual number that is on the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1554,
     "status": "ok",
     "timestamp": 1607718262399,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "4hJjZQEGI35f",
    "outputId": "3a1ba5c8-d469-4de2-a643-8c7f51d00a45"
   },
   "outputs": [],
   "source": [
    "# batch size for the dataloader\n",
    "batch_size = 64\n",
    "\n",
    "# data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, \n",
    "                   transform=transforms.ToTensor()), batch_size=batch_size, \n",
    "                   shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, download=True, \n",
    "                   transform=transforms.ToTensor()), batch_size=batch_size, \n",
    "                   shuffle=False)\n",
    "\n",
    "# print statistics\n",
    "print('The train data consists of %d samples' % len(train_loader.dataset))\n",
    "print('The test data consists of %d samples' % len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VChZ6dD9I35l"
   },
   "source": [
    "Here are a few examples of the data, the corresponding label is on top of each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1550,
     "status": "ok",
     "timestamp": 1607718262400,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "8alfRhgtI35n",
    "outputId": "50e1e038-08c4-4920-f3ee-632c5f3aac34"
   },
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "n = 5\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.imshow(test_loader.dataset[i][0].numpy()[0, ...], cmap='gray')\n",
    "    plt.title(test_loader.dataset[i][1])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIry8iFZI35y"
   },
   "source": [
    "## Building an autoencoder\n",
    "\n",
    "Now, we have to implement the autoencoder and train it. Let's start by defining the architecture. \n",
    "\n",
    "Let's build a straightforward autoencoder with a single hidden layer. Not that every pixel in the image corresponds to an input dimension, i.e. the input and output of the autoencoder will be $28 \\times 28$ dimensional and images will have to be reshaped in vector format. Implement the following architecture: \n",
    "- The first layer (encoder) will be a fully connected layer with sigmoid activation that transforms the input features to a 64 dimensional (hidden) feature vector representation. \n",
    "- The second layer (decoder) is another FC that transforms the hidden representation to the original input dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 1944,
     "status": "ok",
     "timestamp": 1607718262799,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "D_gMrQN3VD10",
    "outputId": "d902d7a7-d676-4bf5-9467-ab4945bb2555"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_input, dim_hidden):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(in_features=dim_input, out_features=dim_hidden), nn.Sigmoid())\n",
    "        self.decoder = nn.Sequential(nn.Linear(in_features=dim_hidden, out_features=dim_input), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        x_ = self.decoder(h)\n",
    "        return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ae = AutoEncoder(28*28, dim_hidden)\n",
    "print(net_ae)\n",
    "\n",
    "# propagate a sample\n",
    "x = test_loader.dataset[i][0].view(-1, 28 * 28)\n",
    "x_ = net_ae(x)\n",
    "\n",
    "# show the result\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x.view(28, 28).numpy(), cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_.view(28, 28).detach().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEMW_Ss7ERHN"
   },
   "source": [
    "Obviously, the networks is generating random noise right now, as it has not yet been trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 64792,
     "status": "ok",
     "timestamp": 1607718325651,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "n8l0jAmOI356",
    "outputId": "f6e74495-ba0b-40c4-a17f-4891ab8bf219"
   },
   "outputs": [],
   "source": [
    "def train_epoch(net, loader, optimizer, criterion, device): \n",
    "    net.train()\n",
    "    loss_avg = 0\n",
    "    for x, _ in loader:\n",
    "        # construct a batch\n",
    "        x = x.view(-1, 28*28).to(device)\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        x_ = net(x)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = criterion(x_, x)\n",
    "\n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_avg += loss.item()\n",
    "    loss_avg = loss_avg / len(loader)\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(net, loader, criterion, device): \n",
    "    net.eval()\n",
    "    loss_avg = 0\n",
    "    for x, _ in loader:\n",
    "        # construct a batch\n",
    "        x = x.view(-1, 28*28).to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        x_ = net(x)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = criterion(x_, x)\n",
    "\n",
    "        loss_avg += loss.item()\n",
    "    loss_avg = loss_avg / len(loader)\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, optimizer, epochs, criterion, device): \n",
    "    train_losses = np.zeros((epochs))\n",
    "    test_losses = np.zeros((epochs))\n",
    "    for epoch in range(epochs):\n",
    "        train_losses[epoch] = train_epoch(net, train_loader, optimizer, criterion, device)\n",
    "        test_losses[epoch] = test_epoch(net, test_loader, criterion, device)\n",
    "        print(\"Epoch %d/%d: Train loss = %.4f - Test loss = %.4f\" \n",
    "              % (epoch + 1, epochs, train_losses[epoch], test_losses[epoch]))\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_ae = net_ae.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net_ae.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train(net_ae, train_loader, test_loader, \n",
    "                              optimizer, epochs, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 64788,
     "status": "ok",
     "timestamp": 1607718325653,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "hSpJsSGrKUMB",
    "outputId": "cc8176c3-63a5-4c00-cc09-67b58e6fb8c6"
   },
   "outputs": [],
   "source": [
    "# propagate a sample\n",
    "net_ae.eval()\n",
    "x = test_loader.dataset[i][0].view(-1, 28 * 28).to(device)\n",
    "x_ = net_ae(x)\n",
    "\n",
    "# show the result\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x.view(28, 28).cpu().numpy(), cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_.view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sck0Kfo3iSOF"
   },
   "source": [
    "The network is able to reconstruct the data fairly decent. The result is slightly blurry, you may play around the loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick two examples from the dataset\n",
    "a = test_loader.dataset[i][0].view(28, 28)\n",
    "b = test_loader.dataset[i+1][0].view(28, 28)\n",
    "\n",
    "# build a grid\n",
    "fig = plt.figure(figsize=(60,5))\n",
    "grid = AxesGrid(fig, 141, nrows_ncols=(1, 11),\n",
    "                axes_pad=0.00, label_mode=\"1\")\n",
    "\n",
    "# interpolate between images\n",
    "for k in range(11):\n",
    "    z = k/10. * a + (1. - k/10.) * b\n",
    "    im = grid[k].imshow(z, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do nearly the same thing, but in a latent space, picking up the low-dimentional representation provided by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get low-dimentional representations\n",
    "x = torch.tensor(a.view(-1, 28 * 28).to(device))\n",
    "a_emb = net_ae.encoder(x)   \n",
    "x = torch.tensor(b.view(-1, 28 * 28).to(device))\n",
    "b_emb = net_ae.encoder(x) \n",
    "\n",
    "fig = plt.figure(figsize=(60,5))\n",
    "grid = AxesGrid(fig, 141, nrows_ncols=(1, 11),\n",
    "                axes_pad=0.00, label_mode=\"1\",)\n",
    "\n",
    "for k in range(11):\n",
    "    # interpolate in latent space\n",
    "    z_emb = k/10. * a_emb + (1. - k/10.) * b_emb\n",
    "    # use the latent code to decode the results\n",
    "    z = net_ae.decoder(z_emb)\n",
    "    im = grid[k].imshow(z.cpu().data.numpy().reshape(28,28), interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXrEb0rTI35-"
   },
   "source": [
    "## Clustering with autoencoders\n",
    "\n",
    "We can cluster data with an autoencoder model, the most straight-forward approach is to cluster the data in the encoded space, e.g. using k-means clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(net, loader):\n",
    "    net.eval()\n",
    "    embeddings = np.zeros((len(loader.dataset), dim_hidden))\n",
    "    b = 0\n",
    "    for x, _ in loader:\n",
    "        x = x.view(-1, 28*28).to(device)\n",
    "        h = net.encoder(x).cpu().detach().numpy()\n",
    "        embeddings[b: b+len(h)] = h\n",
    "        b += len(h)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67385,
     "status": "ok",
     "timestamp": 1607718328254,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "8H8AJGfjI35_",
    "outputId": "40f599f1-ebd3-4d17-b597-449741198431"
   },
   "outputs": [],
   "source": [
    "# compute the embeddings of the autoencoder on the test set\n",
    "h = compute_embeddings(net_ae, test_loader)\n",
    "\n",
    "# cluster the embeddings\n",
    "kmeans = KMeans(n_clusters=10, random_state=seed).fit(h)\n",
    "predictions = kmeans.labels_\n",
    "labels = test_loader.dataset.targets.numpy()\n",
    "\n",
    "# evaluate\n",
    "# ars_ae = adjusted_rand_score(labels, predictions)\n",
    "# print('Adjusted rand score: %.3f' % ars_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52yu_pnXbOGf"
   },
   "source": [
    "The following code will compare the true labels and the clustering results. Note that the colors do not necessarily correspond to the same cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 74189,
     "status": "ok",
     "timestamp": 1607718335062,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "odUbcam-Wb8l",
    "outputId": "2e02dcdd-b013-44fa-e80b-464b1296eda6"
   },
   "outputs": [],
   "source": [
    "# reduce the dimensionality of the hidden representations\n",
    "ld = TSNE(n_components=2, random_state=seed).fit_transform(h[:1000])\n",
    "\n",
    "# visualize the reduced representations and label each sample\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(ld[:, 0], ld[:, 1], c=labels[:1000], cmap='Paired')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=range(10))\n",
    "plt.title('True labels')\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(ld[:, 0], ld[:, 1], c=predictions[:1000], cmap='Paired')\n",
    "plt.title('Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TACB37JMbrl8"
   },
   "source": [
    "Within the encoder, there are connections to each pixel for each hidden variable. In other words, we can visualize which pixels are important to activate a particular hidden variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 75732,
     "status": "ok",
     "timestamp": 1607718336609,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "pd4QpjS5lO7N",
    "outputId": "21f22a3c-7db2-4e18-d61f-4cff1599b6e2"
   },
   "outputs": [],
   "source": [
    "# extract the matrix parameters\n",
    "w = list(net_ae.encoder.parameters())[0]\n",
    "# visualize the features\n",
    "k = 8\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        plt.subplot(k, k, i*k+j+1)\n",
    "        plt.imshow(w[i*k+j,:].view(28, 28).cpu().detach().numpy())\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEU34VvDUPr_"
   },
   "source": [
    "## Semi-supervised classification\n",
    "\n",
    "Semi-supervised classification aims to use large amounts of unlabeled data and a limited amount of labeled data for maximum classification performance. We will see that the extracted features of an autoencoder can serve as suitable features for classification. Moreover, you can use some `sklearn` model to perform the classification, as NNs seems like overkill here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 102749,
     "status": "ok",
     "timestamp": 1607718363631,
     "user": {
      "displayName": "Joris Roels",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiO17HAi3vdM28rwcREixXOvi5CItNho4sxx-YCwkU=s64",
      "userId": "00181780506485155029"
     },
     "user_tz": -60
    },
    "id": "Azcb6-SlVUNv",
    "outputId": "04ffb482-d151-48c7-de59-5f454aa67e5b"
   },
   "outputs": [],
   "source": [
    "def train_svm(x_train, y_train, n):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train[:n], y_train[:n])\n",
    "    return clf\n",
    "\n",
    "def test_svm(clf, x_test, y_test):\n",
    "    predicted = clf.predict(x_test)\n",
    "    acc = metrics.accuracy_score(y_test, predicted)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the embeddings of the autoencoder on the train and test set\n",
    "h_train = compute_embeddings(net_ae, train_loader)\n",
    "h_test = compute_embeddings(net_ae, test_loader)\n",
    "\n",
    "# train and test an SVM for a varying amount of training data\n",
    "n_train_min = 10\n",
    "n_train_max = 200\n",
    "n_train_step = 10\n",
    "n_samples = np.arange(n_train_min, n_train_max, n_train_step)\n",
    "accuracies_ae = np.zeros((len(n_samples)))\n",
    "accuracies_bl = np.zeros((len(n_samples)))\n",
    "for j in range(len(n_samples)):\n",
    "    # autoencoder\n",
    "    clf = train_svm(h_train, train_loader.dataset.targets.numpy(), n_samples[j])\n",
    "    accuracies_ae[j] = test_svm(clf, h_test, test_loader.dataset.targets.numpy())\n",
    "    # baseline\n",
    "    clf = train_svm(train_loader.dataset.data.numpy().reshape((-1, 28*28)), \n",
    "                    train_loader.dataset.targets.numpy(), n_samples[j])\n",
    "    accuracies_bl[j] = test_svm(clf, test_loader.dataset.data.numpy().reshape((-1, 28*28)), \n",
    "                                test_loader.dataset.targets.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_samples, accuracies_ae)\n",
    "plt.plot(n_samples, accuracies_bl)\n",
    "plt.xlabel('Sample size training data')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend(('Autoencoder', 'Baseline'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AutoEncoders",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
